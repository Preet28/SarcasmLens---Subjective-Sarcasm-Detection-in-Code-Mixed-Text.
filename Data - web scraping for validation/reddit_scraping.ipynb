{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f3b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\preet\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting prawcore<3,>=2.4 (from praw)\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update_checker>=0.18 (from praw)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.32.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\preet\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.12.14)\n",
      "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "   ---------------------------------------- 0.0/189.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 189.3/189.3 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: update_checker, prawcore, praw\n",
      "Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install praw pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17813d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reddit Code-Mixed Data Fetcher (SarcasmLens)\n",
    "--------------------------------------------\n",
    "Fetches posts from Indian subreddits that commonly use English + Hindi text.\n",
    "Saves all fetched content into a CSV file and displays a sample DataFrame per subreddit.\n",
    "\n",
    "Requirements:\n",
    "    pip install praw pandas\n",
    "\"\"\"\n",
    "\n",
    "import praw\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ======================================================\n",
    "# 1. Reddit API credentials (from user's Reddit developer app)\n",
    "# ======================================================\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"0Zp33BrXT9ez9Ri2gyC8lg\",              # from Reddit app\n",
    "    client_secret=\"MbuwnN0VBVabcdi-uAPqfp70aJJcAw\",  # from Reddit app\n",
    "    user_agent=\"SarcasmLensApp by u/Naive_Violinist_7239\"  # Preet's reddit username\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e46173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 2. Subreddits and limits\n",
    "# ======================================================\n",
    "subreddits = [\"india\", \"IndianDankMemes\", \"desiHumor\", \"BollywoodMemes\"]\n",
    "limit_per_sub = 100  # number of posts to fetch per subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5b3114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching from r/india ...\n",
      "\n",
      "Sample data from r/india:\n",
      "                                      title  \\\n",
      "0                          Ask India Thread   \n",
      "1  Mental & Emotional Health Support Thread   \n",
      "2               Just got scammed for 45,000   \n",
      "\n",
      "                                       combined_text  \n",
      "0  Ask India Thread Welcome to r/India's Ask Indi...  \n",
      "1  Mental & Emotional Health Support Thread Welco...  \n",
      "2  Just got scammed for 45,000 Like the title sug...  \n",
      "Total posts fetched: 100\n",
      "\n",
      "Fetching from r/IndianDankMemes ...\n",
      "\n",
      "Sample data from r/IndianDankMemes:\n",
      "                            title                   combined_text\n",
      "0             Stop this pollution             Stop this pollution\n",
      "1                 Bachao bachao ðŸ˜°                 Bachao bachao ðŸ˜°\n",
      "2  Manipulating 15yos hell naahhh  Manipulating 15yos hell naahhh\n",
      "Total posts fetched: 100\n",
      "\n",
      "Fetching from r/desiHumor ...\n",
      "\n",
      "Sample data from r/desiHumor:\n",
      "                                         title  \\\n",
      "0  Happy Cakeday, r/Desihumor! Today you're 11   \n",
      "1  Happy Cakeday, r/Desihumor! Today you're 10   \n",
      "2   Happy Cakeday, r/Desihumor! Today you're 9   \n",
      "\n",
      "                                       combined_text  \n",
      "0  Happy Cakeday, r/Desihumor! Today you're 11 Le...  \n",
      "1  Happy Cakeday, r/Desihumor! Today you're 10 Le...  \n",
      "2  Happy Cakeday, r/Desihumor! Today you're 9 Let...  \n",
      "Total posts fetched: 84\n",
      "\n",
      "Fetching from r/BollywoodMemes ...\n",
      "\n",
      "Sample data from r/BollywoodMemes:\n",
      "                                             title  \\\n",
      "0                                       Copy mooli   \n",
      "1  Ye toh arjun kapoor se bhi zada bezati ho gayiðŸ˜¹   \n",
      "2                             Real RAW vs Reel RAW   \n",
      "\n",
      "                                     combined_text  \n",
      "0                                       Copy mooli  \n",
      "1  Ye toh arjun kapoor se bhi zada bezati ho gayiðŸ˜¹  \n",
      "2                             Real RAW vs Reel RAW  \n",
      "Total posts fetched: 100\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 3. Fetches posts\n",
    "# ======================================================\n",
    "all_posts = []\n",
    "\n",
    "for sub in subreddits:\n",
    "    print(f\"\\nFetching from r/{sub} ...\")\n",
    "    posts = []\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "\n",
    "    for submission in subreddit.hot(limit=limit_per_sub):\n",
    "        title = submission.title or \"\"\n",
    "        body = submission.selftext or \"\"\n",
    "        text = (title + \" \" + body).strip()\n",
    "        if text:\n",
    "            posts.append({\n",
    "                \"subreddit\": sub,\n",
    "                \"title\": title,\n",
    "                \"body\": body,\n",
    "                \"combined_text\": text\n",
    "            })\n",
    "\n",
    "    if not posts:\n",
    "        print(f\"No posts fetched from r/{sub}.\")\n",
    "        continue\n",
    "\n",
    "    # Displays a sample (first few rows)\n",
    "    sample_df = pd.DataFrame(posts)\n",
    "    print(f\"\\nSample data from r/{sub}:\")\n",
    "    print(sample_df.head(3)[[\"title\", \"combined_text\"]])\n",
    "    print(f\"Total posts fetched: {len(sample_df)}\")\n",
    "\n",
    "    # Append to global list\n",
    "    all_posts.extend(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "433c736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All posts saved to: data\\reddit_code_mixed_posts.csv\n",
      "Total combined posts: 384\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 4. Combines all subreddits and saves\n",
    "# ======================================================\n",
    "if not all_posts:\n",
    "    print(\"\\nNo posts fetched. Please check credentials or subreddit names.\")\n",
    "else:\n",
    "    df_all = pd.DataFrame(all_posts)\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    output_path = os.path.join(\"data\", \"reddit_code_mixed_posts.csv\")\n",
    "    df_all.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"\\nâœ… All posts saved to: {output_path}\")\n",
    "    print(f\"Total combined posts: {len(df_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e4a4f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Text-only content saved to: data\\reddit_code_mixed_posts.txt\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 5. Saves raw text file\n",
    "# ======================================================\n",
    "text_output = os.path.join(\"data\", \"reddit_code_mixed_posts.txt\")\n",
    "df_all[\"combined_text\"].to_csv(text_output, index=False, header=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Text-only content saved to: {text_output}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
