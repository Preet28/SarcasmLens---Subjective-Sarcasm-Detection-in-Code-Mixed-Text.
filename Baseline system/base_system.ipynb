{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14c24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SarcasmLens: Classical Baselines (Final Subtask 2 Version)\n",
    "# Models: RandomForest, LogisticRegression, LinearSVM, RBFSVM\n",
    "# ===============================\n",
    "\n",
    "# 1Ô∏è‚É£ Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd4dbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Original Dataset Info =====\n",
      "Shape: (11367, 3)\n",
      "Columns: ['ID', 'Tweet', 'Label']\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 2Ô∏è‚É£ Load Dataset (CSV)\n",
    "# ===============================\n",
    "path = r\"C:\\MAIN\\Projects\\Sarcasm Detection\\Dataset\\unique_tweets.csv\"  # <-- change if needed\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(\"\\n===== Original Dataset Info =====\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"=================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ec46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Selected columns: text ‚Üí text | label ‚Üí label\n",
      "Dataset shape after selection: (11367, 2)\n",
      "                                                    text label\n",
      "11362  Khiladi anari, aur shaamat equipment ki aye! B...    NO\n",
      "11363  #irony RT @techno_charan: pallu k neche chhupa...    NO\n",
      "11364                          Jab Thak Hai Jaan. #Irony    NO\n",
      "11365  @beeba_puttar Acha! Aur koi nae mila tha #sarc...    NO\n",
      "11366  @Nirmalogy sacchi mucchi mein? Yah ye bhi #Sar...    NO \n",
      "\n",
      "                                                text label\n",
      "0  takeout burrito shielded from cold as though i...   YES\n",
      "1  sight of coworkers' stupid fucking faces endur...   YES\n",
      "2                                porch ceded to bats   YES\n",
      "3  panicked donald trump jr. tries to cover up co...   YES\n",
      "4  mike gravel can't believe his polling numbers ...   YES \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Automatically detect tweet text and label columns\n",
    "possible_text_cols = [col for col in df.columns if \"tweet\" in col.lower() or \"text\" in col.lower()]\n",
    "possible_label_cols = [col for col in df.columns if \"label\" in col.lower()]\n",
    "\n",
    "text_col = possible_text_cols[0] if possible_text_cols else df.columns[1]\n",
    "label_col = possible_label_cols[0] if possible_label_cols else df.columns[-1]\n",
    "\n",
    "# Subset and rename\n",
    "df = df[[text_col, label_col]]\n",
    "df.columns = [\"text\", \"label\"]\n",
    "\n",
    "print(f\"‚úÖ Selected columns: {text_col} ‚Üí text | {label_col} ‚Üí label\")\n",
    "print(f\"Dataset shape after selection: {df.shape}\")\n",
    "print(df.tail(5), \"\\n\")\n",
    "print(df.head(5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17034eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaning done! Sample cleaned tweets:\n",
      "                                                    text label\n",
      "10763  hahahahhaa rajeev jaise log bas khans' ke pais...    NO\n",
      "6021   baby faced muscular jimmy carter tells democra...   YES\n",
      "3048   bad ass engagement ring also tells the time an...   YES\n",
      "5640       shopper takes bizarre journey beyond bed bath   YES\n",
      "1237   nation flattered brand would go to the trouble...   YES \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 3Ô∏è‚É£ Text Cleaning\n",
    "# ===============================\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)          # Remove URLs\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \"\", text)          # Remove mentions\n",
    "    text = re.sub(r\"#\", \"\", text)                       # Remove hashtags\n",
    "    text = re.sub(r\"[^a-zA-Z\\u0900-\\u097F!?'\\s]\", \" \", text)  # Keep English/Hindi letters, !, ?\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()            # Normalize spaces\n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "print(\"‚úÖ Cleaning done! Sample cleaned tweets:\")\n",
    "print(df.sample(5, random_state=42), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b0ec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 9093 | Test size: 2274\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 4Ô∏è‚É£ Train / Test Split (Stratified)\n",
    "# ===============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"],\n",
    "    df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"],\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)} | Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e918234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 5Ô∏è‚É£ TF-IDF Vectorizer\n",
    "# ===============================\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 2),\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 6Ô∏è‚É£ Define Models\n",
    "# ===============================\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=200, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        max_iter=1000, solver=\"liblinear\", random_state=42\n",
    "    ),\n",
    "    \"LinearSVM\": LinearSVC(\n",
    "        C=1.0, random_state=42\n",
    "    ),\n",
    "    \"RBFSVM\": SVC(\n",
    "        kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0206d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 7Ô∏è‚É£ Track Best Model\n",
    "# ===============================\n",
    "best_model_name = None\n",
    "best_model_pipeline = None\n",
    "best_f1 = 0.0\n",
    "results_summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7222d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üîπ Training RandomForest\n",
      "========================================\n",
      "Accuracy: 0.9565\n",
      "Weighted F1-Score: 0.9567\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO     0.9122    0.9916    0.9503       954\n",
      "         YES     0.9935    0.9311    0.9613      1320\n",
      "\n",
      "    accuracy                         0.9565      2274\n",
      "   macro avg     0.9529    0.9613    0.9558      2274\n",
      "weighted avg     0.9594    0.9565    0.9567      2274\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 946    8]\n",
      " [  91 1229]]\n",
      "\n",
      "========================================\n",
      "üîπ Training LogisticRegression\n",
      "========================================\n",
      "Accuracy: 0.9639\n",
      "Weighted F1-Score: 0.9640\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO     0.9467    0.9686    0.9575       954\n",
      "         YES     0.9769    0.9606    0.9687      1320\n",
      "\n",
      "    accuracy                         0.9639      2274\n",
      "   macro avg     0.9618    0.9646    0.9631      2274\n",
      "weighted avg     0.9642    0.9639    0.9640      2274\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 924   30]\n",
      " [  52 1268]]\n",
      "\n",
      "========================================\n",
      "üîπ Training LinearSVM\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Preet\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9732\n",
      "Weighted F1-Score: 0.9732\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO     0.9646    0.9717    0.9681       954\n",
      "         YES     0.9794    0.9742    0.9768      1320\n",
      "\n",
      "    accuracy                         0.9732      2274\n",
      "   macro avg     0.9720    0.9730    0.9725      2274\n",
      "weighted avg     0.9732    0.9732    0.9732      2274\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 927   27]\n",
      " [  34 1286]]\n",
      "\n",
      "========================================\n",
      "üîπ Training RBFSVM\n",
      "========================================\n",
      "Accuracy: 0.9727\n",
      "Weighted F1-Score: 0.9727\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO     0.9685    0.9665    0.9675       954\n",
      "         YES     0.9758    0.9773    0.9765      1320\n",
      "\n",
      "    accuracy                         0.9727      2274\n",
      "   macro avg     0.9721    0.9719    0.9720      2274\n",
      "weighted avg     0.9727    0.9727    0.9727      2274\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 922   32]\n",
      " [  30 1290]]\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 8Ô∏è‚É£ Training & Evaluation Loop\n",
    "# ===============================\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*40}\\nüîπ Training {name}\\n{'='*40}\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    clf = Pipeline([\n",
    "        (\"tfidf\", tfidf),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    report = classification_report(y_test, y_pred, digits=4)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    \n",
    "    # Store results\n",
    "    results_summary.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"weighted_f1\": f1\n",
    "    })\n",
    "    \n",
    "    # Track best\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model_name = name\n",
    "        best_model_pipeline = clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43479e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üèÜ Best Model: LinearSVM\n",
      "üèÜ Best Weighted F1: 0.9732\n",
      "==================================================\n",
      "\n",
      "‚úÖ All tasks completed successfully!\n",
      "   -> Saved model: best_baseline_model.pkl\n",
      "   -> Results summary: results_summary.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# 9Ô∏è‚É£ Save Best Model & Results\n",
    "# ===============================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "print(f\"üèÜ Best Weighted F1: {best_f1:.4f}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model_pipeline, \"best_baseline_model.pkl\")\n",
    "\n",
    "# Save evaluation summary\n",
    "with open(\"results_summary.json\", \"w\") as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ All tasks completed successfully!\")\n",
    "print(\"   -> Saved model: best_baseline_model.pkl\")\n",
    "print(\"   -> Results summary: results_summary.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
