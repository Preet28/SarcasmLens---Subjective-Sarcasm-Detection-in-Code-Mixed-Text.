{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092b27df",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "610b4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SarcasmLens – Baseline System (Subtask 2)\n",
    "-----------------------------------------\n",
    "Goal:\n",
    "Train and evaluate multiple classical ML models for sarcasm detection in\n",
    "code-mixed (Hindi-English) text using TF-IDF embeddings.\n",
    "\n",
    "Models implemented:\n",
    "1. Random Forest\n",
    "2. Logistic Regression\n",
    "3. Linear SVM\n",
    "4. RBF SVM\n",
    "\n",
    "The code includes:\n",
    "- Data preprocessing and cleaning\n",
    "- TF-IDF vectorization\n",
    "- Model training and evaluation\n",
    "- Saving best model and metrics\n",
    "- Testing on an external test set\n",
    "\"\"\"\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "046064bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Dataset Information =====\n",
      "Shape: (11367, 3)\n",
      "Columns: ['ID', 'Tweet', 'Label']\n",
      "===============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 1. Load Dataset\n",
    "# =======================================================\n",
    "path = r\"C:\\MAIN\\Projects\\Sarcasm Detection\\Dataset\\unique_tweets.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(\"\\n===== Dataset Information =====\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"===============================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2042fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns used: Tweet → text | Label → label\n",
      "Dataset shape after selection: (11367, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Automatically detect text and label columns\n",
    "possible_text_cols = [col for col in df.columns if \"tweet\" in col.lower() or \"text\" in col.lower()]\n",
    "possible_label_cols = [col for col in df.columns if \"label\" in col.lower()]\n",
    "\n",
    "text_col = possible_text_cols[0] if possible_text_cols else df.columns[1]\n",
    "label_col = possible_label_cols[0] if possible_label_cols else df.columns[-1]\n",
    "\n",
    "df = df[[text_col, label_col]]\n",
    "df.columns = [\"text\", \"label\"]\n",
    "\n",
    "print(f\"Columns used: {text_col} → text | {label_col} → label\")\n",
    "print(f\"Dataset shape after selection: {df.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9cf052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning completed. Sample:\n",
      "\n",
      "                                                    text label\n",
      "10763  hahahahhaa rajeev jaise log bas khans' ke pais...    NO\n",
      "6021   baby faced muscular jimmy carter tells democra...   YES\n",
      "3048   bad ass engagement ring also tells the time an...   YES\n",
      "5640       shopper takes bizarre journey beyond bed bath   YES\n",
      "1237   nation flattered brand would go to the trouble...   YES\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 2. Text Cleaning\n",
    "# =======================================================\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by removing URLs, mentions, hashtags, and unwanted symbols.\n",
    "    Retains Hindi + English characters and punctuation (!, ?), as these may carry\n",
    "    sarcastic intent.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)       # Remove URLs\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \"\", text)       # Remove mentions\n",
    "    text = re.sub(r\"#\", \"\", text)                    # Remove hashtags\n",
    "    text = re.sub(r\"[^a-zA-Z\\u0900-\\u097F!?'\\s]\", \" \", text)  # Keep Hindi & English\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()         # Normalize spaces\n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "print(\"Text cleaning completed. Sample:\\n\")\n",
    "print(df.sample(5, random_state=42))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fa36bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 9093, Testing samples: 2274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 3. Train/Test Split\n",
    "# =======================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "461e6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 4. TF-IDF Vectorization\n",
    "# =======================================================\n",
    "\"\"\"\n",
    "TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "represents each document as a weighted vector of tokens.\n",
    "\n",
    "Hyperparameters:\n",
    "- max_features=8000 → limits vocabulary size to the 8000 most frequent tokens.\n",
    "  Prevents overfitting and reduces computation time.\n",
    "- ngram_range=(1,2) → includes unigrams and bigrams, capturing short sarcastic\n",
    "  phrases like \"wah kya\" or \"oh great\".\n",
    "- sublinear_tf=True → applies logarithmic scaling to term frequency, which\n",
    "  helps balance very common vs. rare terms.\n",
    "\"\"\"\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 2),\n",
    "    sublinear_tf=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c04d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 5. Model Definitions\n",
    "# =======================================================\n",
    "\"\"\"\n",
    "Each model has specific hyperparameters chosen for balance between speed and accuracy.\n",
    "1. RandomForestClassifier:\n",
    "   - n_estimators=200 → number of trees; chosen for stable performance without\n",
    "     excessive computation.\n",
    "2. LogisticRegression:\n",
    "   - solver='liblinear' → efficient for small/medium datasets.\n",
    "   - max_iter=1000 → ensures convergence.\n",
    "3. LinearSVC:\n",
    "   - C=1.0 → default regularization strength; higher values risk overfitting.\n",
    "4. SVC (RBF Kernel):\n",
    "   - kernel='rbf' and gamma='scale' → non-linear boundary, useful if sarcasm\n",
    "     distribution is complex.\n",
    "\"\"\"\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, solver=\"liblinear\", random_state=42),\n",
    "    \"LinearSVM\": LinearSVC(C=1.0, random_state=42),\n",
    "    \"RBFSVM\": SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dee8ec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Training RandomForest\n",
      "==============================\n",
      "Accuracy: 0.9565\n",
      "Weighted F1-Score: 0.9567\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO     0.9122    0.9916    0.9503       954\n",
      "         YES     0.9935    0.9311    0.9613      1320\n",
      "\n",
      "    accuracy                         0.9565      2274\n",
      "   macro avg     0.9529    0.9613    0.9558      2274\n",
      "weighted avg     0.9594    0.9565    0.9567      2274\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 946    8]\n",
      " [  91 1229]]\n",
      "\n",
      "==============================\n",
      "Training LogisticRegression\n",
      "==============================\n",
      "Accuracy: 0.9639\n",
      "Weighted F1-Score: 0.9640\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO     0.9467    0.9686    0.9575       954\n",
      "         YES     0.9769    0.9606    0.9687      1320\n",
      "\n",
      "    accuracy                         0.9639      2274\n",
      "   macro avg     0.9618    0.9646    0.9631      2274\n",
      "weighted avg     0.9642    0.9639    0.9640      2274\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 924   30]\n",
      " [  52 1268]]\n",
      "\n",
      "==============================\n",
      "Training LinearSVM\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Preet\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9732\n",
      "Weighted F1-Score: 0.9732\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO     0.9646    0.9717    0.9681       954\n",
      "         YES     0.9794    0.9742    0.9768      1320\n",
      "\n",
      "    accuracy                         0.9732      2274\n",
      "   macro avg     0.9720    0.9730    0.9725      2274\n",
      "weighted avg     0.9732    0.9732    0.9732      2274\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 927   27]\n",
      " [  34 1286]]\n",
      "\n",
      "==============================\n",
      "Training RBFSVM\n",
      "==============================\n",
      "Accuracy: 0.9727\n",
      "Weighted F1-Score: 0.9727\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO     0.9685    0.9665    0.9675       954\n",
      "         YES     0.9758    0.9773    0.9765      1320\n",
      "\n",
      "    accuracy                         0.9727      2274\n",
      "   macro avg     0.9721    0.9719    0.9720      2274\n",
      "weighted avg     0.9727    0.9727    0.9727      2274\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 922   32]\n",
      " [  30 1290]]\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 6. Training and Evaluation\n",
    "# =======================================================\n",
    "best_model_name = None\n",
    "best_model_pipeline = None\n",
    "best_f1 = 0.0\n",
    "results_summary = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n==============================\\nTraining {name}\\n==============================\")\n",
    "    clf = Pipeline([\n",
    "        (\"tfidf\", tfidf),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    results_summary.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"weighted_f1\": f1\n",
    "    })\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model_name = name\n",
    "        best_model_pipeline = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70b58e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tokens extracted by TF-IDF:\n",
      "['prime' 'mexican' 'executives' 'one on' 'itna' 'un ka' 'meri'\n",
      " 'inspired by' 'push' 'struggle' 'politics kiya' 'eyes' 'ek hai' 'never'\n",
      " 'dharmik' 'concert' 'oral' 'fat' 'inki' 'time when']\n"
     ]
    }
   ],
   "source": [
    "# Display token features from the TF-IDF vectorizer\n",
    "tfidf_features = best_model_pipeline.named_steps[\"tfidf\"].get_feature_names_out()\n",
    "print(\"Example tokens extracted by TF-IDF:\")\n",
    "print(np.random.choice(tfidf_features, 20, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afd9006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Best Model: LinearSVM\n",
      "Best Weighted F1: 0.9732\n",
      "========================================\n",
      "\n",
      "\n",
      "Model and metrics saved successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 7. Save Best Model and Results\n",
    "# =======================================================\n",
    "print(\"\\n========================================\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best Weighted F1: {best_f1:.4f}\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "joblib.dump(best_model_pipeline, \"best_baseline_model.pkl\")\n",
    "\n",
    "with open(\"results_summary.json\", \"w\") as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "\n",
    "print(\"\\nModel and metrics saved successfully.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7020fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== External Test Data =====\n",
      "Shape: (2109, 3)\n",
      "Columns: ['ID', 'Tweet', 'Label']\n",
      "\n",
      "===== Test Set Evaluation =====\n",
      "Accuracy: 0.9919\n",
      "Weighted F1: 0.9919\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO     0.9887    0.9873    0.9880       706\n",
      "         YES     0.9936    0.9943    0.9939      1403\n",
      "\n",
      "    accuracy                         0.9919      2109\n",
      "   macro avg     0.9911    0.9908    0.9909      2109\n",
      "weighted avg     0.9919    0.9919    0.9919      2109\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 697    9]\n",
      " [   8 1395]]\n",
      "Predictions saved to test_predictions_with_truth.csv\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# 8. Evaluate on External Test Set\n",
    "# =======================================================\n",
    "test_path = r\"C:\\MAIN\\Projects\\Sarcasm Detection\\Dataset\\test.csv\"\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "print(\"===== External Test Data =====\")\n",
    "print(\"Shape:\", df_test.shape)\n",
    "print(\"Columns:\", df_test.columns.tolist())\n",
    "\n",
    "# Detect text and label columns\n",
    "possible_text_cols = [col for col in df_test.columns if \"tweet\" in col.lower() or \"text\" in col.lower()]\n",
    "possible_label_cols = [col for col in df_test.columns if \"label\" in col.lower()]\n",
    "text_col = possible_text_cols[0] if possible_text_cols else df_test.columns[1]\n",
    "label_col = possible_label_cols[0] if possible_label_cols else None\n",
    "\n",
    "if label_col:\n",
    "    df_test = df_test[[text_col, label_col]]\n",
    "    df_test.columns = [\"text\", \"label\"]\n",
    "else:\n",
    "    df_test = df_test[[text_col]]\n",
    "    df_test.columns = [\"text\"]\n",
    "\n",
    "# Clean test data\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(clean_text)\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model_pipeline.predict(df_test[\"text\"])\n",
    "\n",
    "if \"label\" in df_test.columns:\n",
    "    y_true = df_test[\"label\"]\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(\"\\n===== Test Set Evaluation =====\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Weighted F1: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    df_test[\"predicted_label\"] = y_pred\n",
    "    df_test.to_csv(\"test_predictions_with_truth.csv\", index=False, encoding=\"utf-8\")\n",
    "    print(\"Predictions saved to test_predictions_with_truth.csv\")\n",
    "else:\n",
    "    df_test[\"predicted_label\"] = y_pred\n",
    "    df_test.to_csv(\"test_predictions.csv\", index=False, encoding=\"utf-8\")\n",
    "    print(\"Predictions saved to test_predictions.csv (no true labels).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
